# 캐시 메모리
## 캐시 메모리란?
- 데이터나 값을 복사해 둠으로써 더 빠른 접근을 가능하게 하는 메모리.
  - CPU 바로 옆에 붙어 있어서 속도가 매우 빠르지만, 용량이 매우 적은 편이다.
- 원활히 캐시 메모리를 사용하기 위해 특정 조건 하에서 캐시 메모리를 관리해주어야 한다.
  - 정해진 용량 안에서 최고의 효율성을 얻는 것을 목적으로 한다.

## 캐시 교체 정책
대표적으로 몇 가지 꼽아보자면..
### FIFO(First In First Out)
- 선입선출. 먼저 캐시에 올라왔던 데이터가 먼저 캐시에서 삭제된다.
- 자료구조 중 큐(Queue)와 비슷한 원리로 작동한다.
### LRU(Least Recently Used)
- 가장 오랫동안 쓰이지 않은 데이터가 캐시에서 삭제된다.
### LFU(Least Frequently Used)
- 가장 덜 자주 쓰인 데이터가 캐시에서 삭제된다.

## LRU 캐시 구현
### 가정
- 캐시의 크기와, 가장 오랫동안 참조되지 않은 페이지를 제거하는 로직이 필요하다.
- Doubly-Linked List로 구현할 수 있다.
  - 캐시의 앞에 노드를 더해 주는 것, 캐시의 뒤에서 노드를 제거해주는 것 모두 O(1) 시간 안에 할 수 있기 때문.
### 구현: 검색 캐시
  - 캐시 메모리를 초기화할 때 고정된 크기를 정한다.
  - 검색어를 통해 검색할 경우, 먼저 캐시를 순회하며 해당 검색어가 캐싱되어 있는지 살핀다.
    - 만약 캐싱되어 있다면, 미리 연동해둔 딕셔너리에서 해당 검색어를 키로 가지는 결과값을 반환한다.
    - 이후 해당 노드를 해당 위치에서 지우고, 리스트의 앞에 노드로서 추가한다.
  - 캐시가 꽉 찼고, 현재 검색한 페이지가 캐시 미스가 났을 경우, 가장 뒤의 노드가 제거된다.
  - 덤으로 검색어에 대한 캐시 히트 횟수를 별도의 딕셔너리에 저장해 관리하면 좋다.

## 캐시는 왜 쓸까?
### 딕셔너리 vs 캐시
- 딕셔너리에 대해서 생각해보면, 해시 테이블을 활용한 key-value 데이터베이스 자료형이다.
- LRU 테이블은 “가장 오래 사용되지 않은" 데이터를 제거하는 정책이다. 
  - 같은 용량을 기준으로 했을 때, "사용 여부"를 계산하는 로직이 포함되어야 한다.
- 사용 여부, 즉 데이터의 “나이"를 계산하는 로직 자체가 비용이 많이 들기 때문에, 아무 조건도 없을 때는 딕셔너리가 더 빠르게 작동한다.
- 다만, 캐시 교체 정책은 용량이 한정된 특수한 상황에서 사용된다는 것을 유념할 필요가 있다. 
  - 한정된 용량 하에서는 조금의 비용이 더 들더라도 이러한 교체 정책이 충분히 합리적이라고 여겨진다.

## cf. 연결 리스트(Linked List)
- 데이터와 포인터를 가지고 있는 노드가 한 줄로 연결되어 있는 방식의 자료구조이다.
  - 여기서 포인터는 C에 나오는 그 포인터가 맞다! 다음 노드가 있는 메모리 주소를 참조한다.
- 이러한 성질 때문에, 기존의 배열처럼 연속적인 메모리 주소를 차지할 필요가 없다. 
- 또한 뒤쪽 끝에 데이터를 추가할 때 최악의 경우 O(n)이 걸리는 배열과 달리, 늘 O(1)의 실행 시간을 보장한다.
  - 배열은 append할 때 배열에 할당된 메모리가 꽉 찬 경우, 지금 점유하고 있는 공간의 2배가 되는 메모리 공간으로 이동해야 한다.
  - 배열의 이동은 O(n)의 시간이 소모된다.
- 다만 특정 위치의 데이터를 검색할 때 처음부터 포인터를 타고 원하는 값이 있는 노드까지 훑어야 하기 때문에, O(n)의 시간이 걸린다는 단점이 있다.
  - 배열은 인덱스를 알 경우 O(1) 시간 안에 접근할 수 있다.
- 다음 노드의 주소를 ‘참조’한다는 성질 때문에, Swift에서 연결 리스트를 구현할 때 Node는 class로 만든다.
- 단방향 연결 리스트, 쌍방향 연결 리스트, 원형 연결 리스트 등이 있다.
  - LRU 캐시 구현에 사용된 것은 쌍방향 연결 리스트(Doubly Linked List). 이전 노드와 다음 노드에 대한 포인터를 가지고 있다.